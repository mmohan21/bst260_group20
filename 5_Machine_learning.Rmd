---
title: "Machine learning"
author: "Cheryn Aouaj, Lisa Bebell, Sun Kim, Manasi Mohan"
date: "12/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(caret)
library(plotly)
library(randomForest)
library(nnet)
```

### Some more EDA - Seagrass species in the Great Barrier Reef, 1984-2018

We will now focus our attention on seagrass, and aim to build a classification algorithm to predict presence or absence of any seagrass species in the Great Barrier Reef. We will use location, types of sediment, and types of seabed to predict the presence of four seagrass species: *Cymodocea serrulata*, *Syringodium isoetifolium*, *Thalassia hemprichii*, and *Zostera muelleri* (subspecies *capricorni*).

```{r, warning=FALSE}
# read data
setwd("cleaned_data")
seagrass <- read.csv("seagrass_classification_data.csv", as.is =TRUE)

# factorize relevant variables
seagrass$SPECIES <- as.factor(seagrass$SPECIES)
seagrass$SEDIMENT <- as.factor(seagrass$SEDIMENT)
seagrass$TIDAL <- as.factor(seagrass$TIDAL)

# view data
head(seagrass)
summary(seagrass)
```

First we plot seagrass according to location (latitude and longitude). Then we will add a third axis (water depth) to visualize this in 3-dimensions using the `plotly` package. Since depth is measured in meters below sea level, we visualize this in negative values.

```{r}
seagrass %>%
  ggplot() +
  geom_point(aes(x=LATITUDE, y=LONGITUDE, color=SPECIES)) +
  ggtitle("Australia, Northeast Coast (Great Barrier Reef)")

plot_ly(seagrass, x=~LATITUDE, y=~LONGITUDE, z=~-DEPTH, color=~SPECIES, type="scatter3d", mode="markers")
```

We can also see how our categorical predictors, sediment and seabed type, relate to the number of observed seagrass species:

```{r}
seagrass %>% 
  ggplot(aes(SEDIMENT, fill=SPECIES)) +
  geom_bar(width=.5, position = "dodge")

seagrass %>% 
  ggplot(aes(TIDAL, fill=SPECIES)) +
  geom_bar(width=.5, position = "dodge")
```

### Random Forest

Our first attempt at the classifier (to predict presence of any seagrass species) will use random forest. We will first partition the data set into a training and testing set. Since we have over 12,000 observations, we can allocate 75% of the data to the training set.

```{r}
# train-test split
seagrass_train_ind <- createDataPartition(y = seagrass$SPECIES, p=0.75, list=FALSE)

train_set <- seagrass[seagrass_train_ind, ]
test_set <- seagrass[-seagrass_train_ind, ]

# fit RF using relevant features, with mtry~p/3
rf_fit <- randomForest(SPECIES ~ LATITUDE + LONGITUDE + DEPTH + SEDIMENT + TIDAL, 
                       data=train_set, mtry = 2)

# build vector of predictions
rf_pred <- predict(rf_fit, newdata = test_set, type = "response")

# view performance metrics
confusionMatrix(table(pred = rf_pred, true = test_set$SPECIES))
```

We see that our classification model works quite well, especially for `T_HEMPRICH` and `Z_CAPRICOR`, which have 85%+ sensitivity and specificity. However, this model got quite a low sensitivity for `S_ISOETIFO`. Recall from our data wrangling process that `S_ISOETIFO` had only about 100 "Yes" observations. Since we thus had low variation in the values of `S_ISOETIFO` relative to the other three seagrass species, this may have contributed to the low sensitivity. 

We can visually assess our predicted values with true values of species to see how our model performed.

```{r}
# true values
plot_ly(test_set, x=~LATITUDE, y=~LONGITUDE, z=~-DEPTH, color=~SPECIES, type="scatter3d", mode="markers")

# predicted values
plot_ly(test_set, x=~LATITUDE, y=~LONGITUDE, z=~-DEPTH, color=~rf_pred, type="scatter3d", mode="markers")
```

These plots look fairly similar across the training and test sets, for all four species.

Below we see that across sediment types, the species predictions (rf_pred) appear very similar to the true species distribution (SPECIES). The same is true across seabed types, in the two bar graphs further below. 

```{r}
test_set %>% 
  ggplot(aes(SEDIMENT, fill=SPECIES)) +
  geom_bar(width=.5, position = "dodge")

test_set %>% 
  ggplot(aes(SEDIMENT, fill=rf_pred)) +
  geom_bar(width=.5, position = "dodge")
```
```{r}
test_set %>% 
  ggplot(aes(TIDAL, fill=SPECIES)) +
  geom_bar(width=.5, position = "dodge")

test_set %>% 
  ggplot(aes(TIDAL, fill=rf_pred)) +
  geom_bar(width=.5, position = "dodge")
```

Finally, we examine variable importance using the Gini coefficient:
```{r}
variable_importance <- importance(rf_fit)

tmp <- data_frame(feature = rownames(variable_importance),
                  Gini = variable_importance[,1]) %>%
                  arrange(desc(Gini))

tmp %>% ggplot(aes(x=reorder(feature, Gini), y=Gini)) + 
  geom_bar(stat='identity') +
  coord_flip() + xlab("Feature") +
  theme(axis.text=element_text(size=8))
```

We see that longitude and latitude were very predictive of presence of seagrass followed by water depth. The types of sediment and seabed are not very important predictors. Thus, it seems that the location of where the sea grass was discovered matters more than the various ocean floor properties.


### Multinomial logistic regression

We will now try a multinomial logistic regression model to see how it compares to the random forest we fit above. We will use the `nnet` package. The logistic regression model is as follows:

```{r}
# fit model
multinom_fit <- multinom(SPECIES ~ LATITUDE + LONGITUDE + DEPTH + SEDIMENT, data=train_set)
summary(multinom_fit)

# predicted probabilities
predicted_prob <- predict(multinom_fit, newdata=test_set, type="probs")

# predicted classes
predicted_class <- predict(multinom_fit, newdata=test_set, type="class")

# classification performance metrics
confusionMatrix(data = predicted_class, reference = test_set$SPECIES )
```

We see that our multinomial logistic model has about 91% overall accuracy, which is worse performance than the random forest. The model seems to predict `T_HEMPRICH` the best with 88.7% sensitivity and 98.8% specificity. It peforms well for `Z_CAPRICOR` as well, but performs relatively poorly for `C_SERRULAT` and even worse for `S_ISOETIFO` with 0% sensitivity. Again, we can assess our results visually:

```{r}
# true values
plot_ly(test_set, x=~LATITUDE, y=~LONGITUDE, z=~-DEPTH, color=~SPECIES, type="scatter3d", mode="markers")

# predicted values
plot_ly(test_set, x=~LATITUDE, y=~LONGITUDE, z=~-DEPTH, color=~predicted_class, type="scatter3d", mode="markers")
```

In this case, the truth and prediction plots look different, particularly in that the prediction plot does not appear to show any instances of `S_ISOETIFO`. This makes sense, given the small sample size and low variability in the values of the `S_ISOETIFO` variable.


Below we see that across sediment types, the species predictions (rf_pred) appear fairly similar to the true species distribution (SPECIES). This is not true across seabed types, in the two bar graphs further below - there we see that `S_ISOETIFO` is never predicted, and `C_SERRULAT` is predicted less often than in the truth.

```{r}
test_set %>% 
  ggplot(aes(SEDIMENT, fill=SPECIES)) +
  geom_bar(width=.5, position = "dodge")

test_set %>% 
  ggplot(aes(SEDIMENT, fill=predicted_class)) +
  geom_bar(width=.5, position = "dodge")
```

```{r}
test_set %>% 
  ggplot(aes(TIDAL, fill=SPECIES)) + 
  geom_bar(width=.5, position = "dodge")

test_set %>% 
  ggplot(aes(TIDAL, fill=predicted_class)) + 
  geom_bar(width=.5, position = "dodge")
```

The overall accuracy for the multinomial logistic regression model was 90.9%, and that of the random forest model was 95.6%. While these may seem fairly close, the accuracy for the multinomial logistic model is deceiving since it performed particularly poorly in terms of sensitivity in 2 out of 4 classes.

